{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "754e4023-87b8-47b5-b44a-eb1e9ec0f7a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.datasource import DataSource, DataSourceReader, DataSourceWriter\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from typing import Iterator, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f747d3a-a223-4d3a-893d-a25a851623fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def caesar_cypher(text: str, shift: int, decrypt: bool = True):\n",
    "    \"\"\"\n",
    "    Aplica a Cifra de César a uma string de texto.\n",
    "\n",
    "    Esta função pode tanto cifrar quanto decifrar o texto fornecido, dependendo do valor do parâmetro 'decrypt'.\n",
    "\n",
    "    Parâmetros:\n",
    "    - text (str): A string de texto que será processada.\n",
    "    - shift (int): O número de posições que cada letra será deslocada no alfabeto.\n",
    "    - decrypt (bool, opcional): Se True, a função decifra o texto; se False, cifra o texto. O padrão é True.\n",
    "\n",
    "    Retorna:\n",
    "    - str: O texto resultante após a aplicação da Cifra de César.\n",
    "\n",
    "    Exemplo de uso:\n",
    "    >>> caesar_cypher('abc', 3)\n",
    "    'xyz'\n",
    "    >>> caesar_cypher('xyz', 3, decrypt=True)\n",
    "    'abc'\n",
    "    \"\"\"\n",
    "    if not decrypt:\n",
    "        shift *= -1\n",
    "    result = []\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            effective_shift = shift % 26\n",
    "            base_code = ord('a') if char.islower() else ord('A')\n",
    "            new_char = chr(base_code + (ord(char) - base_code - effective_shift) % 26)\n",
    "            result.append(new_char)\n",
    "        else:\n",
    "            result.append(char)\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb759fe6-3c1a-4abf-9188-3a689d06cd24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CypherDataSourceReader(DataSourceReader):\n",
    "    \"\"\"\n",
    "    A custom DataSourceReader for reading and decrypting files encrypted with the Caesar Cypher.\n",
    "\n",
    "    This class reads encrypted text files and applies the Caesar Cypher decryption based on the provided shift value.\n",
    "\n",
    "    Attributes:\n",
    "        schema (StructType): The schema of the DataFrame to be returned.\n",
    "        options (dict): A dictionary of options, including 'path' to the file and 'shift' for decryption.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, schema: StructType, options: dict):\n",
    "        \"\"\"\n",
    "        Initializes the CypherDataSourceReader with the given schema and options.\n",
    "\n",
    "        Args:\n",
    "            schema (StructType): The schema of the DataFrame.\n",
    "            options (dict): A dictionary containing 'path' to the encrypted file and 'shift' value for decryption.\n",
    "        \"\"\"\n",
    "        self.schema = schema\n",
    "        self.options = options\n",
    "\n",
    "    def read(self, partition: int) -> Iterator[Tuple[str]]:\n",
    "        \"\"\"\n",
    "        Reads the encrypted file and yields decrypted lines as tuples.\n",
    "\n",
    "        Args:\n",
    "            partition (int): The partition number (not used in this implementation).\n",
    "\n",
    "        Yields:\n",
    "            Iterator[Tuple[str]]: An iterator over tuples containing decrypted lines of text.\n",
    "        \"\"\"\n",
    "        # Retrieve the file path and shift value from options\n",
    "        file_path = self.options.get(\"path\")\n",
    "        shift = int(self.options.get(\"shift\", 3))\n",
    "        decrypt = self.options.get(\"decrypt\", \"true\").lower() == \"true\"\n",
    "        if not file_path:\n",
    "            raise ValueError(\"No file path provided in options.\")\n",
    "\n",
    "        # Read the file and apply decryption\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                decrypted_text = caesar_cypher(line.strip(), shift, decrypt=decrypt)\n",
    "                yield (decrypted_text,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a23b1069-08f6-4580-95d4-736eb88c6853",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CypherDataSource(DataSource):\n",
    "    \"\"\"\n",
    "    A custom DataSource for reading files encrypted with the Caesar Cypher.\n",
    "\n",
    "    This class allows Spark to read encrypted text files by applying the Caesar Cypher decryption during the read process.\n",
    "\n",
    "    Methods:\n",
    "        name: Returns the short name identifier for the data source.\n",
    "        schema: Defines the schema of the DataFrame to be returned.\n",
    "        reader: Creates a DataSourceReader instance for reading data.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def name(cls):\n",
    "        \"\"\"\n",
    "        Returns the short name identifier for the data source.\n",
    "\n",
    "        Returns:\n",
    "            str: The short name 'cypher'.\n",
    "        \"\"\"\n",
    "        return \"cypher\"\n",
    "\n",
    "    def schema(self):\n",
    "        \"\"\"\n",
    "        Defines the schema of the DataFrame to be returned.\n",
    "\n",
    "        Returns:\n",
    "            StructType: A StructType object defining the schema with a single field 'decrypted_text' of type String.\n",
    "        \"\"\"\n",
    "        return StructType([StructField(\"decrypted_text\", StringType(), True)])\n",
    "\n",
    "    def reader(self, schema: StructType):\n",
    "        \"\"\"\n",
    "        Creates a DataSourceReader instance for reading data.\n",
    "\n",
    "        Args:\n",
    "            schema (StructType): The schema of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            DataSourceReader: An instance of CypherDataSourceReader initialized with the provided schema and options.\n",
    "        \"\"\"\n",
    "        return CypherDataSourceReader(schema, self.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86ed92d4-5784-4946-87a9-ebc91263e244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.dataSource.register(CypherDataSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1acb92d-2c98-4420-bc46-bf1d5b5ddebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_decrypted = (spark.read.format(\"cypher\")\n",
    "                .option(\"shift\", 5)\n",
    "                .load(\"test_encrypted.txt\"))\n",
    "\n",
    "display(df_decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7b99d9-15ff-464f-ace8-25f0c80e8a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_decrypted = (spark.read.format(\"cypher\")\n",
    "                .option(\"shift\", 3)\n",
    "                .option(\"decrypt\", False)\n",
    "                .load(\"test.txt\"))\n",
    "\n",
    "display(df_decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecd4bd5f-049a-4bd3-9433-d4cb81f2dc28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CypherDataSource",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
